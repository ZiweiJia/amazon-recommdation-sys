{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_reviews: 8898041\n",
      "n_reviewer: 603668\n",
      "n_books: 367982\n"
     ]
    }
   ],
   "source": [
    "# sc.stop()\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     input_json_path = sys.argv[1]\n",
    "#     output_json_path = sys.argv[2]\n",
    "    sc = SparkContext.getOrCreate()  \n",
    "#     try:\n",
    "#         sc\n",
    "#     except NameError:\n",
    "#         sc = SparkContext(\"local[*]\",\"PySpark Tutorial\")\n",
    "    time_start = time.time()\n",
    "    input_json_path = 'Books_5.json'\n",
    "    lines = sc.textFile(input_json_path).coalesce(8).persist()\n",
    "    n_lines = lines.count()\n",
    "    print('n_reviews:',n_lines)\n",
    "    json_read = lines.map(lambda line: json.loads(line))\n",
    "    reviewer_id_count = json_read.map(lambda line: (line['reviewerID'], 1)).reduceByKey(lambda a, b:a + b).count()\n",
    "    print('n_reviewer:',reviewer_id_count)\n",
    "    asin_count = json_read.map(lambda line: (line['asin'], 1)).reduceByKey(lambda a, b:a + b).count()\n",
    "    print('n_books:',asin_count)\n",
    "    time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777.650279045105"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_end-time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_reviews: 200000\n",
      "n_reviewer: 113228\n",
      "n_books: 5894\n"
     ]
    }
   ],
   "source": [
    "# sc.stop()\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     input_json_path = sys.argv[1]\n",
    "#     output_json_path = sys.argv[2]\n",
    "    sc = SparkContext.getOrCreate()  \n",
    "#     try:\n",
    "#         sc\n",
    "#     except NameError:\n",
    "#         sc = SparkContext(\"local[*]\",\"PySpark Tutorial\")\n",
    "    time_start = time.time()\n",
    "    input_json_path = 'split_0.json'\n",
    "    lines = sc.textFile(input_json_path).coalesce(8).persist()\n",
    "    n_lines = lines.count()\n",
    "    print('n_reviews:',n_lines)\n",
    "    json_read = lines.map(lambda line: json.loads(line))\n",
    "    reviewer_id_count = json_read.map(lambda line: (line['reviewerID'], 1)).reduceByKey(lambda a, b:a + b).count()\n",
    "    print('n_reviewer:',reviewer_id_count)\n",
    "    asin_count = json_read.map(lambda line: (line['asin'], 1)).reduceByKey(lambda a, b:a + b).count()\n",
    "    print('n_books:',asin_count)\n",
    "    time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.154645681381226"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_end-time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_reviewer: 113228\n",
    "# n_books: 5894\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "input_json_path = 'split_0.json'\n",
    "n_reviewer = 113228\n",
    "n_books = 5894\n",
    "array = np.zeros((1,1))\n",
    "\n",
    "reviewer_dict = {}\n",
    "book_dict = {}\n",
    "# with open(input_json_path,'r',encoding='utf=8') as f:\n",
    "#     i = 0\n",
    "#     j = 0\n",
    "#     for line in f.readlines():\n",
    "#         line = json.loads(line)\n",
    "#         if line[\"reviewerID\"] not in reviewer_dict:\n",
    "#             reviewer_dict[line[\"reviewerID\"]] = i\n",
    "#             i += 1\n",
    "#         if line[\"asin\"] not in book_dict:\n",
    "#             book_dict[line[\"asin\"]] = j\n",
    "#             j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_json_path,'r',encoding='utf=8') as f:\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 5000\n",
    "    for line in f.readlines():\n",
    "        lines = json.loads(line)\n",
    "        if k == 0:\n",
    "            break\n",
    "        if lines[\"reviewerID\"] not in reviewer_dict:\n",
    "            reviewer_dict[lines[\"reviewerID\"]] = i\n",
    "            i += 1\n",
    "            array = np.column_stack((array,np.zeros((array.shape[0],1))))\n",
    "        if lines[\"asin\"] not in book_dict:\n",
    "            book_dict[lines[\"asin\"]] = j\n",
    "            j += 1\n",
    "            array = np.row_stack((array,np.zeros((1, array.shape[1]))))\n",
    "        array[book_dict[lines[\"asin\"]],reviewer_dict[lines[\"reviewerID\"]]] = lines[\"overall\"]\n",
    "        k -= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 4880)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm,solve,svd\n",
    "def get_Ur_hat(A, c, r):\n",
    "#     Ur_hat\n",
    "#     A matrix, c draw c columns, r num of top eigenvectors\n",
    "    if c<1 or r<1:\n",
    "        c,r = 1, 1\n",
    "    draw_c_cols = []\n",
    "    col_prob = norm(A, ord=2, axis=0)**2/norm(A)**2\n",
    "    col_range = range(0, A.shape[1])\n",
    "    col_to_choose = np.random.choice(col_range, c, p=col_prob)\n",
    "    draw_c_cols = A[:, col_to_choose]\n",
    "    if r == c:\n",
    "        Ur_u, Ur_sigma, Ur_v = svd(draw_c_cols, full_matrices=False)\n",
    "    else:\n",
    "        Ur_u, Ur_sigma, Ur_v = svds(draw_c_cols, k=r)\n",
    "    return Ur_u\n",
    "\n",
    "def get_Vr_hat(A, c, r):\n",
    "#     Vr_hat\n",
    "#     A matrix, c draw c rows, r num of top eigenvectors\n",
    "    if c<1 or r<1:\n",
    "        c,r = 1, 1\n",
    "    draw_c_rows = []\n",
    "    row_prob = norm(A, ord=2, axis=1)**2/norm(A)**2\n",
    "    row_range = range(0, A.shape[0])\n",
    "    row_to_choose = np.random.choice(row_range, c, p=row_prob)\n",
    "    draw_c_rows = A[row_to_choose,:]\n",
    "    if r==c:\n",
    "        Vr_u, Vr_sigma, Vr_v = svd(draw_c_rows,full_matrices=False)\n",
    "    else:\n",
    "        Vr_u, Vr_sigma, Vr_v = svds(draw_c_rows, k=r)\n",
    "    return Vr_v\n",
    "\n",
    "Ur_hat = get_Ur_hat(array, int(array.shape[0]/10), int(array.shape[0]/10)-1)\n",
    "# print(Ur_hat)\n",
    "Vr_hat = get_Vr_hat(array, int(array.shape[0]/10), int(array.shape[0]/10)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.38304317e-16, -3.20694129e-17,  1.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.28656769e-01,  9.73507104e-01,  1.52467617e-16],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-9.73507104e-01,  2.28656769e-01,  1.74438484e-16],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ur_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.12993039e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.91740415e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.71585269e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vr_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
